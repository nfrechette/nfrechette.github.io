---
layout: post
title: temp title
---
Optimizing Sin and Cos

Today we will take an in depth look at optimized Sin and Cos functions. They need no introduction, everybody knows what they do. It comes as no surprise that they are heavily used in games for all sorts of things. While C standard library provides an implementation for these, they sadly take as an input a `double` when more often than not in games, we only care about `float`. The side effect of course is that to call the function, we must coerce our value back and forth, something that is never fast. Even though the C++ standard provides overloads for using `float`, internally coercion happens automatically for you.

To avoid this and keep things fast, it is thus desirable to implement fast implementations which will approximate the desired result as close as possible. Again we will use the excellent [DirectX Math](https://github.com/Microsoft/DirectXMath) library as a reference and take a deep dive into how to make them faster.

All the involved code can be found on GitHub [here](https://github.com/nfrechette/DirectXMathOptimizations).

Our test cases
Our functions
  ScalarSin
    Scalar C
    SSE
    FMA
  VectorSin
    SSE
    FMA
  ScalarCos
    Scalar C
    SSE
    FMA
  VectorCos
    SSE
    FMA
Conclusion

# Our test cases

Because trigonometric functions are very short (and sweet!), we’ll focus on calling it a whole lot with various randomly generated inputs. We generate 512 scalar or vector inputs depending on the version we are testing. The first 16 are hardcoded values that test boundary edge cases and the rest are randomly generated in the range of `[-4PI .. 4PI]`.

Each test run will process our inputs **100000** times in a tight loop. This will be considered **1** sample and we will generate **100** samples. Just like in our last post, we will use the **80th** percentile as the measure of our performance. Everything fits within our L1 cache and as such the timings should be consistent (aside from OS and frequency noise).

I ran everything on my desktop computer which has an [Intel i7-6850K processor](https://ark.intel.com/products/94188/Intel-Core-i7-6850K-Processor-15M-Cache-up-to-3_80-GHz). While my CPU differs from what the Xbox One and PlayStation 4 use, they both support AVX and could benefit from similar changes but you’ll need to profile first! In particular, the faster scalar implementations on my CPU were not what I expected and remembered seeing on the Xbox One.

Our single thread was pinned to a core and ran uninterrupted on my idle system.

All my raw results are parsed with a simple python script to extract the desired percentile and format it in a table form. The script can be found [here](https://github.com/nfrechette/DirectXMathOptimizations/blob/master/parse_stats.py).

*  ScalarSin: [raw data](/public/trigonometry/results_scalarsin_raw.csv), [parsed data](/public/trigonometry/results_scalarsin.csv), [charts](/public/trigonometry/results_scalarsin.xlsx)
*  VectorSin: [raw data](/public/trigonometry/results_vectorsin_raw.csv), [parsed data](/public/trigonometry/results_vectorsin.csv), [charts](/public/trigonometry/results_vectorsin.xlsx)
*  ScalarCos: [raw data](/public/trigonometry/results_scalarcos_raw.csv), [parsed data](/public/trigonometry/results_scalarcos.csv), [charts](/public/trigonometry/results_scalarcos.xlsx)
*  VectorCos: [raw data](/public/trigonometry/results_vectorcos_raw.csv), [parsed data](/public/trigonometry/results_vectorcos.csv), [charts](/public/trigonometry/results_vectorcos.xlsx)

# Our functions

I focused on keeping the results binary exact with the reference implementation. For our scalar flavors, they come in 3 forms: scalar C math, SSE math, and FMA math. Our vector flavors only come with SSE and FMA.

Both the scalar C math and the SSE math implementations are binary exact but as I was playing around, I thought that giving FMA a try might prove interesting. However, as a result these functions are no longer binary exact although they are very close. Of course, FMA stands for [fused-multiply and add]() and it is available in modern Intel processors (but sadly not in the Xbox One nor the PlayStation 4).

It might be possible to make these even faster. I was more concerned with improving what was there and measuring the results than I was in writing the ultimate end-all versions.

Most of the emphasis was placed on the Sin flavors since Cos is very similar. For Cos, I generally took the best performing Sin implementations and used the same tricks in each category.

## ScalarSin

### Our reference

<script src="https://gist.github.com/nfrechette/4330dffebdfd5e98d13ba0b60405c28a.js"></script>

The function performs three things in sequential order.

Step one: the lines 3 to 10 take our input argument and narrows it down to the range `[-PI .. PI]`. As you’ll recall, sin and cos are both periodic. Narrowing down the range of values is necessary in order to use a high precision minimax approximation later. This step is simple, we first divide by **2PI** (line 4, done by multiplying the reciprocal), we perform symmetric rounding on lines 5 to 8, and finally we remove the number of periodic cycles on line 10.

Symmetric rounding is perhaps the most well-known rounding method. It works as follow:
Round(-1.00) = -1.0
Round(-0.75) = -1.0
Round(-0.50) = -1.0
Round(-0.25) = 0.0
Round(0.00) = 0.0
Round(0.25) = 0.0
Round(0.50) = 1.0
Round(0.75) = 1.0
Round(1.00) = 1.0

Each value rounds to the nearest integer and values halfway between integers round away from zero.

Step two: the lines 12 to 16 take the previous value and further narrows it down to the range `[-PI/2 .. PI/2]`. Both sin and cos are symmetric within the range `[-PI .. PI]` and again this allows us to use a higher precision minimax in the third and final step. Here the code simply mirrors the value based on where it lies.

Step three: the lines 19 and 20 calculate our minimax result. I won’t go into further details about how this works as there is plenty of reference material out there already. We’ll simply accept that this is an implementation detail we’ll be working with.

The reference implementation does not automatically inline despite being marked as such. It is likely too big. As such, all further versions we will test will be forced to not inline as to make measuring easier unless otherwise mentioned.

### Scalar C++

Without trying to use intrinsic functions, there are a few things we can try. Namely we can see if perhaps we can remove or reduce the branching and there is also some sub-optimal assembly being generated.

The first branch: [V00]( https://github.com/nfrechette/DirectXMathOptimizations/blob/master/Inc/ScalarSin/ScalarSin_CPP_V00.h), 

## VectorSin

### Our reference

## ScalarCos

### Our reference

## VectorCos

### Our reference

# Conclusion


